---
title: "Untitled"
output:
  pdf_document: default
  html_document: default
---

Implement your model in this file when it is your final decision about it.

# setup
```{r,warning = FALSE}
library(drpm)
library(salso)

# preparation
source("include.R") # for having df_agri
source("plot functions/plotter.R")
```

```{r}
source("include_clusters_functions.R")
```

# y and sites
needed for plots functions
```{r}
time_span = c(1:53)

sites = data.frame(
	longitude = unique(df_weekly$Longitude), 
	latitude = unique(df_weekly$Latitude))

std_sites = data.frame(
	longitude = unique(df_wsc$Longitude), 
	latitude = unique(df_wsc$Latitude))

stations = unique(df_wsc$IDStations)
y=data.frame()

for(st in stations){
  y_we_pm10=cbind(as.data.frame(st),t(df_wsc[which(df_wsc$IDStations==st),"AQ_pm10"]))
  y=rbind(y,y_we_pm10)
}

rownames(y) = NULL
colnames(y)<- c("id",paste0("w", 1:53))
df_wsc
y
plot(sites)
plot(std_sites)

sites_plt = sites
colnames(sites_plt) = c("Longitude","Latitude")
rownames(sites_plt) = paste(1:105)

salso_out_lists = list()
```



```{r}
cols = colora(105,56,show=F)
chosen_variable_name = "AQ_pm10"
trendYearStation_week <- function(file_name){
	data_from_to = df_wsc
	len_time = 53
	chosen_variable = (data_from_to[,chosen_variable_name])
	# Crea il grafico ggplot
	station_trend <- ggplot(data_from_to,aes(x = week, 
												 y = AQ_pm10,
												 group=IDStations, 
												 color = as.factor(IDStations))) +
		geom_line(show.legend = FALSE) +
		labs(x = "Stations", y = chosen_variable_name, title = "Year: 2018 all stations") +
		ylim(range(na.omit(chosen_variable))) +
		scale_color_manual(values = cols) +
		theme_bw()+
		theme(panel.grid = element_blank()) +
		guides(color = guide_legend())+
		labs(x="week")

	len_time = (len_time%/%5)
	return(trend_animator(file_name,station_trend, data_from_to$week,len_time))
}
trendYearStation_week("None")
```


```{r}
# install.packages("ggrepel")
library(ggrepel)

# p_stations_codes = 
	# ggplot()+
	# geom_sf(data = altre_regioni, fill = color_empty ,color = color_fill,
	# 		linewidth = 0.1,alpha=0.1, show.legend = FALSE) +
	# geom_sf(data = lombardia_2, fill = color_empty, color = color_comuni_lombardia,
	# 		linewidth = 0.3,alpha=0.7, show.legend = FALSE) +
	# coord_sf(xlim = range(sites$longitude) + padding,
	# 		 ylim = range(sites$latitude) + padding, expand = FALSE)+
	# theme_bw()+
	# theme(panel.grid = element_blank())+
p_stations_codes =
	DefaultPlot()+
	geom_point(data = sites_plt, aes(x = Longitude, y = Latitude, color = "col"), size = 1)+
	theme(legend.position = "none")+
	geom_text_repel(data = sites_plt, aes(x = Longitude, y = Latitude, col="col",
										  label = rownames(sites_plt)),
					size = 3,
					max.overlaps = 100,
					min.segment.length = 0
					# force_pull =2,
					# force = 10,
					)+
	scale_colour_manual(name="",values = c("col"="#aa0010"))+
	# scale_colour_manual(name="",values = c("col"="#1022a1"))+
	labs(title = "Stations codes")
p_stations_codes
```


```{r}
# print(p_stations_codes)
# ggsave(file="figures/stations_names_visualized.pdf",height=6, width=6)
# ggsave(file="figures/stations_names_visualized.png",units="px",height=1500, width=1500)
# dev.off()
```

#=======
# DRPM + experimentation

```r
> log(40)
3.688879
> mean(df_weekly$AQ_pm10)
[1] 3.223147
> var(df_weekly$AQ_pm10)
[1] 0.2295554
> (3.688879-3.223147)/sqrt(0.2295554)
[1] 0.9720583
```
This last value should be the one for us to check if some station went over the limit of PM10, which is 40 μg m^(-3). But that 40 needed to be log-trasformed and scaled for us in the new data setting.
Maybe we can add an horizontal line in the boxplot to show it if we want.

Model obtained collecting 1000 mcmc iterates, using niter=60000; nburn=20000; nthin=40.
```{r}
# load("../data/Federico/drpm_eta0_phi1_spcoes5.Rdata")
# load("../data/Federico/drpm_eta0_phi1_spcoes5_v2.Rdata")

base_folder = "DRPM"

load("../data/Federico/drpm_eta0_phi1_spcoes5.Rdata")
# questo resta il migliore, ma forse su certi tempi si può lavorare in modo adaptive
# cambiando abinder o a mano in qualche modo
# perché gli altri test di fit hanno suggerito altre divisioni interessanti, in certi tempi

drpm_model = drpm1 # was called drpm1 inside the rdata
cat(crayon::red("\nLPML =",drpm_model$lpml, "\nWAIC =",drpm_model$waic))
```


After some tuning this salso configuration should be the best.
Ie the one with binder loss with a=1.2, while the default a=1 was not so good. 
Increasing a (max is a=2) means that we penalize more the case where units get wrongly divided in separate clusters if instead should have been together (like a strict false negative, or something similar, contrasint).

```{r}
abinder = rep(1.2,53)
abinder[19] = 1.3
abinder[21] = 1.3
abinder[22] = 1.3
abinder[40] = 1.1
abinder[43] = 1.3
abinder[44] = 1.5
abinder[45] = 1.3
abinder[50] = 1.5
abinder[52] = 1.4
abinder[53] = 1.4
# plot(abinder,type="l")

exclude=list()
for (i in 1:53){
	exclude[[i]]=list()
}

exclude[[1]][[1]] = c(80,52)
exclude[[2]][[1]] = c(80)
exclude[[3]][[1]] = c(80)
exclude[[4]][[1]] = c(80,52)
exclude[[5]][[1]] = c(80)
exclude[[6]][[1]] = c(80)

exclude[[7]][[2]] = c(92,101)
exclude[[8]][[2]] = c(92,101)
exclude[[9]][[2]] = c(92,101)
exclude[[10]][[2]] = c(92,101)
exclude[[11]][[2]] = c(92,101)
exclude[[12]][[2]] = c(92,101)
exclude[[13]][[2]] = c(92,101)
exclude[[14]][[1]] = c(92,101)
exclude[[15]][[1]] = c(92,101)
exclude[[16]][[1]] = c(92,101)

exclude[[7]][[1]] = c(80)
exclude[[8]][[1]] = c(80)
exclude[[9]][[1]] = c(80)
exclude[[10]][[1]] = c(80)
exclude[[11]][[1]] = c(80)
exclude[[12]][[1]] = c(80)
exclude[[13]][[1]] = c(80)

exclude[[44]][[1]] = c(101,92)

exclude[[46]][[1]] = c(92,101)

exclude[[47]][[1]] = c(92,101)
exclude[[47]][[2]] = c(80)

exclude[[48]][[1]] = c(92,101)

exclude[[51]][[1]] = c(92,101)
exclude[[51]][[2]] = c(80,52)

exclude[[52]][[1]] = c(92,101)
exclude[[52]][[2]] = c(80,52)

exclude[[53]][[1]] = c(92,101)
exclude[[53]][[2]] = c(80,20,69)
```

## cls see
```{r}
df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span[1]){

	salso_out = rep(0,105)
	if(length(exclude[[time]])==0 ){
		cat("no touch\n")
		salso_out <- salso(t(drpm_model$Si[time,,]),
					   loss=binder(),
					   # loss=binder(a=abinder[time]), # chosen one, better
					   maxNClusters = 8
					   )
	} else {
		cat("correction\n")
		exclude_st = Reduce(union,exclude[[time]])
		
		# salso_out[-exclude_st] <- salso(t(drpm_model$Si[time,-exclude_st,]),
		salso_out <- salso(t(drpm_model$Si[time,,]),
					   # loss=binder(),
					   loss=binder(a=abinder[time]), # chosen one, better
					   maxNClusters = 6
					   )
		curr_n_clusters = max(salso_out[-exclude_st])
		for(i in 1:length(exclude[[time]])){
			curr_n_clusters = curr_n_clusters+1
			salso_out[exclude[[time]][[i]]] = curr_n_clusters
		}
	}
	# easy_plot(salso_out)
	
	df_temp = data.frame(
		Longitude = sites$longitude,
		Latitude = sites$latitude,
		clusters = salso_out[1:105]
	)
	df_temp$Time = rep(time,dim(df_temp)[1])
	df_cluster = rbind(df_cluster,df_temp)
	
	# clusters log
	clusters_now = df_temp$clusters
	# n_clusters = max(clusters_now)
	n_clusters = unique(clusters_now)
	ycurrent = y[,paste0("w",time)]
	cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
	# for (cl in n_clusters){
		# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
			# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
	# }
	
	df_cluster_cut = df_temp
	cols = color_correct_clusters(df_cluster_cut,idea=2,verbose=0,nint=15)
	p = plot_graph_and_hist(df_cluster_cut,cols,jittera = T)

	# plot_intensities(df_cluster_cut,verbose=T)
}
```



## cls def
```{r,warning=F}
salso_out_list = list()
salso_out_matrix = matrix(NA,nrow=53,ncol=105)

df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){

	# salso_out <- salso(t(drpm_model$Si[time,,]),
	# 				   # loss=binder(),
	# 				   loss=binder(a=abinder[time]), # chosen one, better
	# 				   maxNClusters = 6
	# 				   )
	salso_out = rep(0,105)
	if(length(exclude[[time]])==0 ){
		cat("no touch\n")
		salso_out <- salso(t(drpm_model$Si[time,,]),
					   # loss=binder(),
					   loss=binder(a=abinder[time]), # chosen one, better
					   maxNClusters = 6
					   )
	} else {
		cat("correction\n")
		exclude_st = Reduce(union,exclude[[time]])
		
		# salso_out[-exclude_st] <- salso(t(drpm_model$Si[time,-exclude_st,]),
		salso_out <- salso(t(drpm_model$Si[time,,]),
					   # loss=binder(),
					   loss=binder(a=abinder[time]), # chosen one, better
					   maxNClusters = 6
					   )
		curr_n_clusters = max(salso_out[-exclude_st])
		for(i in 1:length(exclude[[time]])){
			curr_n_clusters = curr_n_clusters+1
			salso_out[exclude[[time]][[i]]] = curr_n_clusters
		}
	}
	salso_out_list[[time]] = salso_out
	salso_out_matrix[time,] = salso_out
	

	################################################
	df_temp = data.frame(
		Longitude = sites$longitude,
		Latitude = sites$latitude,
		clusters = salso_out[1:105]
	)
	# increment nint until there is no error
	cols = color_correct_clusters(df_temp,idea=2,verbose=0,nint=12)
	
	df_temp$Time = rep(time,dim(df_temp)[1])
	df_cluster = rbind(df_cluster,df_temp)
	
	# clusters log
	clusters_now = df_temp$clusters
	
	# n_clusters = max(clusters_now)
	n_clusters = unique(clusters_now)
	ycurrent = y[,paste0("w",time)]
	cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
	# for (cl in n_clusters){
		# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
			# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
	# }

}
```
```{r}
salso_out_lists[["DRPM"]] = salso_out_list
```

## time series
```{r}
cl_regions = list()
for (i in 1:10){
	cl_regions[[i]] = numeric()
}

tssites = sites_plt
tssites$cl = rep(0,105)

for (st in 1:105){
	mo = Mode(salso_out_matrix[,st])
	# cat("Station",st,"has mode cluster label equal to",mo,"\n")
	cl_regions[[mo]] = c(cl_regions[[mo]],st)
	tssites$cl[st] = mo
}

## manual changes if we want to separately study some suspitious stations
cl_regions[[1]] = setdiff(cl_regions[[1]],80)
cl_regions[[5]] = 80
tssites$cl[80] = 5

cl_regions
```

```{r}
for(a in 1:3){
if(a==1)
png(file=paste0("figures/",base_folder,"/Time series/Time series.png"),units="px",width = 1200, height = 600)
else if (a==2){
pdf(file=paste0("figures/",base_folder,"/Time series/Time series.pdf"),width = 14, height = 6)
} else {
svg(file=paste0("figures/",base_folder,"/Time series/Time series.svg"),width = 14, height = 6)
}

layout(matrix(c(1,1,1,1,1,1,2,2,2,2,2,2), nrow = 1, byrow = T))
# layout(matrix(c(1,2),nrow = 1, byrow = T),widths=c(6,5))
cols = colora(12,"div",0)[-2]

ys = matrix(NA,nrow=length(cl_regions),53)
stdevys = matrix(NA,nrow=length(cl_regions),53)
for (i in 1:length(cl_regions)){
	ys[i,] = apply(y[cl_regions[[i]],2:54],2,mean)
	stdevys[i,] = sqrt(apply(y[cl_regions[[i]],2:54],2,var))
}
alfa = 100

plot(ys[1,],type="l",ylim=extrema(na.omit(ys))+c(-0.3,+0.1),col=cols[1],lwd=2,xlab="",ylab="")
title(xlab="Weeks",ylab="PM10 values", mgp=c(2.5,2.5,0),cex.lab=1.2)

polygon(c(1:53,53:1), c(ys[1,]-1/2*stdevys[1,],rev(ys[1,]+1/2*stdevys[1,])),
		col = rgb(as.vector(col2rgb(cols[1]))[1],as.vector(col2rgb(cols[1]))[2],
				  as.vector(col2rgb(cols[1]))[3],alfa,maxColorValue = 255),
	border = NA)
lines(ys[1,],type="l",ylim=extrema(na.omit(ys)),col=cols[1],lwd=2)

for (i in 2:length(cl_regions)){
	points(ys[i,],type="l",col=cols[i],lwd=2)
	polygon(c(1:53,53:1), c(ys[i,]-1/2*stdevys[i,],rev(ys[i,]+1/2*stdevys[i,])),
		col = rgb(as.vector(col2rgb(cols[i]))[1],as.vector(col2rgb(cols[i]))[2],
				  as.vector(col2rgb(cols[i]))[3],alfa,maxColorValue = 255),
	border = NA)
}

frame()
# PP1 = DefaultPlot()+
# geom_point(data = tssites, aes(x = Longitude, y = Latitude, color = cols[tssites$cl]), size = 4)+
# theme(legend.position = "none")+
# labs(title = "Stations partitioned")+
# 	scale_colour_identity(guide="legend",labels=paste0("cl",length(unique(tssites$cl))),
# 						  breaks=cols[length(unique(tssites$cl))])
df_cluster_cut = data.frame(
	Longitude = sites$longitude,
	Latitude = sites$latitude,
	clusters = tssites$cl,
	Time = 1
)
cols_gr = cols[1:length(unique(tssites$cl))]
PP1 = get_graph_plot(df_cluster_cut,titolo = "Cluster partition map",cols=cols_gr,verbose=0)

vps <- baseViewports()
pushViewport(vps$inner, vps$figure, vps$plot)
# Table grob
grob <-  ggplotGrob(PP1)
grid.draw(grob)
popViewport(3)

dev.off()
}
```


## salso plots
```{r}
for(time in time_span){

	salso_out = salso_out_list[[time]]
	################################################
	cat(crayon::red("Time",time,"- #clusters =",length(unique(salso_out[1:105])),"\n"))

	ssout = summary(salso_out)
	png(filename=paste0("./figures/DRPM/Salso/Salso-",sprintf("%02d",time),".png"),width=600,height=500)

	# plot(ssout,type="heatmap")
	# plot(ssout,type="mds")
	plot(ssout,type="pairs",data=std_sites)
	text(0.3,0.98,paste0("Time ",time," - ",base_folder))
	# plot(ssout,type="dendrogram")
	
	dev.off()
}
```



## ARI plot
```{r}
### ARI #######################################################################
library(mclust) # if Adjusted RI

LEN = max(time_span)
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(time in 1:LEN){
	rho_ARI[[time]] = salso_out_list[[time]]
}
for(k in 1: LEN){
	for(kk in 1: LEN){
		ARImats[k,kk] <- adjustedRandIndex(rho_ARI[[k]], rho_ARI[[kk]])
	}
}
ncols_ari = 100
cols_ARI = colora(ncols_ari,79,0)
# cols_ARI = rev(cols_ARI)
brks = seq(-1,1,length.out=ncols_ari+1)

for(a in 1:2){
if(a==1)
png(paste0("./figures/",base_folder,"/ARI/ari.png"), width=700,height=600)
else {
svg(paste0("./figures/",base_folder,"/ARI/ari.svg"), height=7, width=8)
}

	library(fields)
image.plot(ARImats,
		   main=paste0("Lagged ARI values - ",base_folder),axes=FALSE,col=cols_ARI,
		   breaks=brks)
mtext(text=c(paste("",1:LEN)), side=2, line=0.3,at=seq(0,1,length=LEN), las=1, cex=0.7)
mtext(text=c(paste("",1:LEN)), side=1, line=0.3,at=seq(0,1,length=LEN), las=2, cex=0.7)
dev.off()
}
```


## cls save
```{r}
clusters_old = NULL
for(time in time_span){
	cat(crayon::red("Time",time,"\n"))

	df_cluster_cut = df_cluster[df_cluster$Time==time,]
	# clusters_now = df_cluster_cut$clusters
	####### no mode correct if heat plot
	# clusters_now = mode_correct_clusters(clusters_old,clusters_now,very_verbose = 0)
	# se fai heat plot non serve fare la mode correct
	# perché la heat plot la usi per vedere anche i valori di pm10, non la coerenza temporale
	# nei gruppi, che con la heat coloration si perde come visibilità (non so se è chiaro)
	# df_cluster_cut$clusters = clusters_now

	cur_num = sprintf("%02d", time)
	cols = color_correct_clusters(df_cluster_cut,idea=2,verbose=0,nint=12)
	
	### Graph
	q = get_graph_plot(df_cluster_cut,cols,paste("Cluster map, time",time,"-",base_folder))
	print(q)
	ggsave(file=paste0("./figures/",base_folder,"/Graph/Graph-",cur_num,".png"),
	units="px",width=2000, height=1400, dpi=300)
	dev.off()
	
	
	### Graph and Boxplot
	p = plot_graph_and_hist(df_cluster_cut,cols,titolo=paste("Time",time,"-",base_folder))
	ggsave(file=paste0("./figures/",base_folder,"/Graph and Boxplot/Graph and Boxplot-",cur_num,".png"),
		   plot=p,
		   units="px",width=2500, height=1200, dpi=300) # maybe 1200 is better
		   # units="px",width=2500, height=1400, dpi=300)
	dev.off()

clusters_old = clusters_now
}
```

## build gif
```{r}
percorso = paste0("./figures/Federico/DRPM/Graph")
# percorso = paste0("./figures/Federico/DRPM/Salso")
# percorso = paste0("./figures/Federico/DRPM/Graph and Boxplot")
output_name = "Graph"
# output_name = "Salso"
# output_name = "Graph and Boxplot"

###################################
# build gif
###################################
# Carica i pacchetti
library(magick)
library(animation)
library(gifski)
library(av)

## list file names and read in
imgs <- list.files(path = percorso, pattern = ".png", full.names = TRUE)
img_list <- lapply(imgs, image_read)

## join the images together
img_joined <- image_join(img_list)

## animate at 1 frames per second. 1 to freely control the fps/framerate later
img_animated <- image_animate(img_joined, fps = 1)

## view animated image
# img_animated

## save to disk
# delay is the inverse of framerate
frammeratte = 2
image_write_gif(image = img_animated, path = paste0(percorso,output_name,".gif"),delay=1/frammeratte)
image_write_video(image = img_animated, path = paste0(percorso,output_name,".mp4"),framerate=frammeratte)
```

## covariates plots
relevant covariates
```{r}
# install.packages("svglite")
library(svglite)

for(time in time_span){
	cat(crayon::red("Time",time,"\n"))

	df_cluster_cut = df_cluster[df_cluster$Time==time,]
	# clusters_now = df_cluster_cut$clusters
	####### no mode correct if heat plot
	# clusters_now = mode_correct_clusters(clusters_old,clusters_now,very_verbose = 0)
	# se fai heat plot non serve fare la mode correct
	# perché la heat plot la usi per vedere anche i valori di pm10, non la coerenza temporale
	# nei gruppi, che con la heat coloration si perde come visibilità (non so se è chiaro)
	# df_cluster_cut$clusters = clusters_now

	cur_num = sprintf("%02d", time)
	cols = color_correct_clusters(df_cluster_cut,idea=2,verbose=0,nint=12)
	
	p = Federica_covariates_plot(df_cluster_cut,cols,
					 titolo = paste("Cluster map, time",time,"-",base_folder),var_selected_idxs)
	# ggsave(p,file="test.png",)
	# ggsave(file=paste0("./figures/",base_folder,"/With Covariates/With Covariates-",cur_num,".svg"),p,width=15, height=10)
	ggsave(p,file=paste0("./figures/",base_folder,"/With Covariates/With Covariates-",cur_num,".png"),units="px",width=4500, height=3000, dpi=400)
	dev.off()

}
```







#=======
# sPPM
```{r}
load("../data/sppm_c4_list.RData")
# see sppm_C4_list[[time]]$Si
```

```{r}
lpml_tot_sppm = waic_tot_sppm = 0
for (time in 1:53){
	lpml_tot_sppm = lpml_tot_sppm + sppm_C4_list[[time]]$lpml
	waic_tot_sppm = waic_tot_sppm + sppm_C4_list[[time]]$WAIC
}
cat(crayon::red("\nLPML =",lpml_tot_sppm, "\nWAIC =",waic_tot_sppm))
# niente ancora lontani da drpm
```


## cls def/see
Here you should tune the salso(ecc) to maybe improve the cluster generation
```{r}
salso_out_list = list()
salso_out_matrix = matrix(NA,nrow=53,ncol=105)

df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){
	
	# tune here your cluster generation
	salso_out <- salso(sppm_C4_list[[time]]$Si,
				   loss=binder(a=1.2),
				   maxNClusters = 8
				   )

	salso_out_list[[time]] = salso_out
	salso_out_matrix[time,] = salso_out

	df_temp = data.frame(
		Longitude = sites$longitude,
		Latitude = sites$latitude,
		clusters = salso_out[1:105]
	)
	# increment nint until there is no error
	cols = color_correct_clusters(df_temp,idea=2,verbose=0,nint=15)
	
	################################################
	
	df_temp$Time = rep(time,dim(df_temp)[1])
	df_cluster = rbind(df_cluster,df_temp)
	
	# clusters log
	clusters_now = df_temp$clusters
	# n_clusters = max(clusters_now)
	n_clusters = unique(clusters_now)
	ycurrent = y[,paste0("w",time)]
	cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
	# for (cl in n_clusters){
		# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
			# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
	# }

	
	################################################
	
	df_cluster_cut = df_temp 
	# if you want to see results directly here, use these lines
	
	# df_cluster_cut = df_cluster[df_cluster$Time==time,] # same def
	# cols = ... defined above

	# salso_out = salso_out_list[[time]]
	# ssout = summary(salso_out)
	# plot(ssout,type="heatmap")
	# plot(ssout,type="mds")
	# plot(ssout,type="pairs",data=std_sites)
	# text(0.2,0.98,paste0("Time ",time))
	# plot(ssout,type="dendrogram")

	# q = get_graph_plot(df_cluster_cut,cols)
	# print(q)
	# p = plot_graph_and_hist(df_cluster_cut,cols)
}
```


## plots save
```{r}
base_folder = "sPPM"
salso_out_lists[[base_folder]] = salso_out_list
```

### ari
```{r}
### ARI #######################################################################
library(mclust) # if Adjusted RI

LEN = max(time_span)
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(time in 1:LEN){
	rho_ARI[[time]] = salso_out_list[[time]]
}
for(k in 1: LEN){
	for(kk in 1: LEN){
		ARImats[k,kk] <- adjustedRandIndex(rho_ARI[[k]], rho_ARI[[kk]])
	}
}
ncols_ari = 100
cols_ARI = colora(ncols_ari,79,0)
# cols_ARI = rev(cols_ARI)
brks = seq(-1,1,length.out=ncols_ari+1)

for(a in 1:2){
if(a==1)
png(paste0("./figures/",base_folder,"/ARI/ari.png"), width=700,height=600)
else {
svg(paste0("./figures/",base_folder,"/ARI/ari.svg"), height=7, width=8)
}

	library(fields)
image.plot(ARImats,
		   main=paste0("Lagged ARI values - ",base_folder),axes=FALSE,col=cols_ARI,
		   breaks=brks)
mtext(text=c(paste("",1:LEN)), side=2, line=0.3,at=seq(0,1,length=LEN), las=1, cex=0.7)
mtext(text=c(paste("",1:LEN)), side=1, line=0.3,at=seq(0,1,length=LEN), las=2, cex=0.7)
dev.off()
}
```

### time series
```{r}
cl_regions = list()
for (i in 1:10){
	cl_regions[[i]] = numeric()
}

tssites = sites_plt
tssites$cl = rep(0,105)

for (st in 1:105){
	mo = Mode(salso_out_matrix[,st],verbose=1)
	cat(crayon::red("Station",st,"has mode cluster label equal to",mo,"\n"))
	cl_regions[[mo]] = c(cl_regions[[mo]],st)
	tssites$cl[st] = mo
}
```


```{r}
## manual changes if we want to separately study some suspitious stations

cl_regions
```

```{r}
### Time series ###############################################################
library(grid)
library(gridBase)
library(gridExtra)

for(a in 1:3){
if(a==1)
png(file=paste0("figures/",base_folder,"/Time series/Time series.png"),units="px",width = 1200, height = 600)
else if (a==2){
pdf(file=paste0("figures/",base_folder,"/Time series/Time series.pdf"),width = 14, height = 6)
} else {
svg(file=paste0("figures/",base_folder,"/Time series/Time series.svg"),width = 14, height = 6)
}

	
layout(matrix(c(1,1,1,1,1,1,2,2,2,2,2,2), nrow = 1, byrow = T))
# layout(matrix(c(1,2),nrow = 1, byrow = T),widths=c(6,5))
cols = colora(12,"div",0)[-2]

ys = matrix(NA,nrow=length(cl_regions),53)
stdevys = matrix(NA,nrow=length(cl_regions),53)
for (i in 1:length(cl_regions)){
	ys[i,] = apply(y[cl_regions[[i]],2:54],2,mean)
	stdevys[i,] = sqrt(apply(y[cl_regions[[i]],2:54],2,var))
}
alfa = 100

plot(ys[1,],type="l",ylim=extrema(na.omit(ys))+c(-0.3,+0.1),col=cols[1],lwd=2,xlab="",ylab="")
title(xlab="Weeks",ylab="PM10 values", mgp=c(2.5,2.5,0),cex.lab=1.2)

polygon(c(1:53,53:1), c(ys[1,]-1/2*stdevys[1,],rev(ys[1,]+1/2*stdevys[1,])),
		col = rgb(as.vector(col2rgb(cols[1]))[1],as.vector(col2rgb(cols[1]))[2],
				  as.vector(col2rgb(cols[1]))[3],alfa,maxColorValue = 255),
	border = NA)
lines(ys[1,],type="l",ylim=extrema(na.omit(ys)),col=cols[1],lwd=2)

for (i in 2:length(cl_regions)){
	points(ys[i,],type="l",col=cols[i],lwd=2)
	polygon(c(1:53,53:1), c(ys[i,]-1/2*stdevys[i,],rev(ys[i,]+1/2*stdevys[i,])),
		col = rgb(as.vector(col2rgb(cols[i]))[1],as.vector(col2rgb(cols[i]))[2],
				  as.vector(col2rgb(cols[i]))[3],alfa,maxColorValue = 255),
	border = NA)
}

frame()
# PP1 = DefaultPlot()+
# geom_point(data = tssites, aes(x = Longitude, y = Latitude, color = cols[tssites$cl]), size = 4)+
# theme(legend.position = "none")+
# labs(title = "Stations partitioned")+
# 	scale_colour_identity(guide="legend",labels=paste0("cl",length(unique(tssites$cl))),
# 						  breaks=cols[length(unique(tssites$cl))])
df_cluster_cut = data.frame(
	Longitude = sites$longitude,
	Latitude = sites$latitude,
	clusters = tssites$cl,
	Time = 1
)
cols_gr = cols
PP1 = get_graph_plot(df_cluster_cut,titolo = "Clusters partition map",cols=cols_gr,verbose=0)

vps <- baseViewports()
pushViewport(vps$inner, vps$figure, vps$plot)
# Table grob
grob <-  ggplotGrob(PP1)
grid.draw(grob)
popViewport(3)

dev.off()
}
```

### the rest
```{r}
for(time in time_span){
	cat(crayon::red("Time",time,"\n"))

	df_cluster_cut = df_cluster[df_cluster$Time==time,]
	# clusters_now = df_cluster_cut$clusters
	####### no mode correct if heat plot
	# clusters_now = mode_correct_clusters(clusters_old,clusters_now,very_verbose = 0)
	# se fai heat plot non serve fare la mode correct
	# perché la heat plot la usi per vedere anche i valori di pm10, non la coerenza temporale
	# nei gruppi, che con la heat coloration si perde come visibilità (non so se è chiaro)
	# df_cluster_cut$clusters = clusters_now

	cur_num = sprintf("%02d", time)
	cols = color_correct_clusters(df_cluster_cut,idea=2,verbose=0,nint=15)

	
	### Salso
	salso_out = salso_out_list[[time]]
	ssout = summary(salso_out)
	png(filename=paste0("./figures/",base_folder,"/Salso/Salso-",sprintf("%02d",time),".png"),
		width=600,height=500)
	# plot(ssout,type="heatmap")
	# plot(ssout,type="mds")
	plot(ssout,type="pairs",data=std_sites)
	text(0.3,0.98,paste0("Time ",time," - ",base_folder))
	# plot(ssout,type="dendrogram")
	dev.off()
	
	
	### Graph
	q = get_graph_plot(df_cluster_cut,cols,paste("Cluster map, time",time,"-",base_folder))
	print(q)
	ggsave(file=paste0("./figures/",base_folder,"/Graph/Graph-",cur_num,".png"),
	units="px",width=2000, height=1400, dpi=300)
	dev.off()
	
	
	### Graph and Boxplot
	p = plot_graph_and_hist(df_cluster_cut,cols,titolo=paste("Time",time,"-",base_folder))
	ggsave(file=paste0("./figures/",base_folder,"/Graph and Boxplot/Graph and Boxplot-",cur_num,".png"),
		   plot=p,
		   units="px",width=2500, height=1200, dpi=300) # maybe 1200 is better
		   # units="px",width=2500, height=1400, dpi=300)
	dev.off()
	
	### Covariates
	p = Federica_covariates_plot(df_cluster_cut,cols,
					 titolo = paste("Cluster map, time",time,"-",base_folder),var_selected_idxs)
	ggsave(p,file=paste0("./figures/",base_folder,"/With Covariates/With Covariates-",cur_num,".png"),units="px",width=4500, height=3000, dpi=400)
	dev.off()
}
```



#=======
# Gaussian PPmx
```{r}
gppmx_fit = readRDS("Gaussian_ppmX.RData")
# read rho through gppmx_fit[[time]]$Si
var_selected <- c("Altitude","EM_nox_sum","WE_mode_wind_direction_100m",
				  "WE_wind_speed_100m_max", "LA_lvi")
```

```{r}
lpml_tot_gppmx = waic_tot_gppmx = 0
for (time in 1:53){
	lpml_tot_gppmx = lpml_tot_gppmx + gppmx_fit[[time]]$lpml
	waic_tot_gppmx = waic_tot_gppmx + gppmx_fit[[time]]$WAIC
}
cat(crayon::red("\nLPML =",lpml_tot_gppmx, "\nWAIC =",waic_tot_gppmx))
# niente ancora lontani da drpm
```


## cls def/see
Here you should tune the salso(ecc) to maybe improve the cluster generation
```{r}
salso_out_list = list()
salso_out_matrix = matrix(NA,nrow=53,ncol=105)

df_cluster = data.frame(Longitude=c(),Latitude=c(),values=c(),clusters=c(),Time=c())
for(time in time_span){
	
	# tune here your cluster generation
	salso_out <- salso(gppmx_fit[[time]]$Si,
				   loss=binder(a=1.2), # example of a tuning
				   maxNClusters = 8
				   )

	salso_out_list[[time]] = salso_out
	salso_out_matrix[time,] = salso_out

	df_temp = data.frame(
		Longitude = sites$longitude,
		Latitude = sites$latitude,
		clusters = salso_out[1:105]
	)
	# increment nint until there is no error
	cols = color_correct_clusters(df_temp,idea=2,verbose=0,nint=12)
	
	################################################
	
	df_temp$Time = rep(time,dim(df_temp)[1])
	df_cluster = rbind(df_cluster,df_temp)
	
	# clusters log
	clusters_now = df_temp$clusters
	# n_clusters = max(clusters_now)
	n_clusters = unique(clusters_now)
	ycurrent = y[,paste0("w",time)]
	cat(crayon::red("Time",time,"- #clusters =",length(unique(clusters_now)),"\n"))
	# for (cl in n_clusters){
		# cat("Cluster",cl,"- size",length(ycurrent[which(clusters_now==cl)]),
			# "- mean",mean(ycurrent[which(clusters_now==cl)]),"\n")
	# }

	
	################################################
	
	df_cluster_cut = df_temp 
	# if you want to see results directly here, use these lines
	
	# df_cluster_cut = df_cluster[df_cluster$Time==time,] # same def
	# cols = ... defined above

	# salso_out = salso_out_list[[time]]
	# ssout = summary(salso_out)
	# plot(ssout,type="heatmap")
	# plot(ssout,type="mds")
	# plot(ssout,type="pairs",data=std_sites)
	# text(0.2,0.98,paste0("Time ",time))
	# plot(ssout,type="dendrogram")

	# q = get_graph_plot(df_cluster_cut,cols)
	# print(q)
	# p = plot_graph_and_hist(df_cluster_cut,cols)
	
	################################################
	# test for covariates plots
	
	# png("test.png",units="px",height = 2400,width = 2000)
	# p = Federica_covariates_plot(df_cluster_cut,cols,
	# 				 titolo = paste("Cluster map, time",time,"- Gaussian PPMx"),var_selected_idxs)
	# ggsave(p,file="test.png",units="px",width=3500, height=3000, dpi=400)
	# ggsave(p,file="test.pdf",width=15, height=10)
	# dev.off()

}
```




## plots save
```{r}
base_folder = "Gaussian PPMx"
salso_out_lists[[base_folder]] = salso_out_list
```

### ari
```{r}
### ARI #######################################################################
library(mclust) # if Adjusted RI

LEN = max(time_span)
# build the ARI matrix
ARImats <- matrix(NA, nrow=LEN, ncol=LEN)
rho_ARI <- list()
for(time in 1:LEN){
	rho_ARI[[time]] = salso_out_list[[time]]
}
for(k in 1: LEN){
	for(kk in 1: LEN){
		ARImats[k,kk] <- adjustedRandIndex(rho_ARI[[k]], rho_ARI[[kk]])
	}
}
ncols_ari = 100
cols_ARI = colora(ncols_ari,79,0)
# cols_ARI = rev(cols_ARI)
brks = seq(-1,1,length.out=ncols_ari+1)

for(a in 1:2){
if(a==1)
png(paste0("./figures/",base_folder,"/ARI/ari.png"), width=700,height=600)
else {
svg(paste0("./figures/",base_folder,"/ARI/ari.svg"), height=7, width=8)
}

	library(fields)
image.plot(ARImats,
		   main=paste0("Lagged ARI values - ",base_folder),axes=FALSE,col=cols_ARI,
		   breaks=brks)
mtext(text=c(paste("",1:LEN)), side=2, line=0.3,at=seq(0,1,length=LEN), las=1, cex=0.7)
mtext(text=c(paste("",1:LEN)), side=1, line=0.3,at=seq(0,1,length=LEN), las=2, cex=0.7)
dev.off()
}
```

### time series
```{r}
cl_regions = list()
for (i in 1:10){
	cl_regions[[i]] = numeric()
}

tssites = sites_plt
tssites$cl = rep(0,105)

for (st in 1:105){
	mo = Mode(salso_out_matrix[,st],verbose=1)
	cat(crayon::red("Station",st,"has mode cluster label equal to",mo,"\n"))
	cl_regions[[mo]] = c(cl_regions[[mo]],st)
	tssites$cl[st] = mo
}
```


```{r}
## manual changes if we want to separately study some suspitious stations

cl_regions
```

```{r}
### Time series ###############################################################
library(grid)
library(gridBase)
library(gridExtra)

for(a in 1:3){
if(a==1)
png(file=paste0("figures/",base_folder,"/Time series/Time series.png"),units="px",width = 1200, height = 600)
else if (a==2){
pdf(file=paste0("figures/",base_folder,"/Time series/Time series.pdf"),width = 14, height = 6)
} else {
svg(file=paste0("figures/",base_folder,"/Time series/Time series.svg"),width = 14, height = 6)
}

	
layout(matrix(c(1,1,1,1,1,1,2,2,2,2,2,2), nrow = 1, byrow = T))
# layout(matrix(c(1,2),nrow = 1, byrow = T),widths=c(6,5))
cols = colora(12,"div",0)[-2]

ys = matrix(NA,nrow=length(cl_regions),53)
stdevys = matrix(NA,nrow=length(cl_regions),53)
for (i in 1:length(cl_regions)){
	ys[i,] = apply(y[cl_regions[[i]],2:54],2,mean)
	stdevys[i,] = sqrt(apply(y[cl_regions[[i]],2:54],2,var))
}
alfa = 100

plot(ys[1,],type="l",ylim=extrema(na.omit(ys))+c(-0.3,+0.1),col=cols[1],lwd=2,xlab="",ylab="")
title(xlab="Weeks",ylab="PM10 values", mgp=c(2.5,2.5,0),cex.lab=1.2)

polygon(c(1:53,53:1), c(ys[1,]-1/2*stdevys[1,],rev(ys[1,]+1/2*stdevys[1,])),
		col = rgb(as.vector(col2rgb(cols[1]))[1],as.vector(col2rgb(cols[1]))[2],
				  as.vector(col2rgb(cols[1]))[3],alfa,maxColorValue = 255),
	border = NA)
lines(ys[1,],type="l",ylim=extrema(na.omit(ys)),col=cols[1],lwd=2)

for (i in 2:length(cl_regions)){
	points(ys[i,],type="l",col=cols[i],lwd=2)
	polygon(c(1:53,53:1), c(ys[i,]-1/2*stdevys[i,],rev(ys[i,]+1/2*stdevys[i,])),
		col = rgb(as.vector(col2rgb(cols[i]))[1],as.vector(col2rgb(cols[i]))[2],
				  as.vector(col2rgb(cols[i]))[3],alfa,maxColorValue = 255),
	border = NA)
}

frame()
# PP1 = DefaultPlot()+
# geom_point(data = tssites, aes(x = Longitude, y = Latitude, color = cols[tssites$cl]), size = 4)+
# theme(legend.position = "none")+
# labs(title = "Stations partitioned")+
# 	scale_colour_identity(guide="legend",labels=paste0("cl",length(unique(tssites$cl))),
# 						  breaks=cols[length(unique(tssites$cl))])
df_cluster_cut = data.frame(
	Longitude = sites$longitude,
	Latitude = sites$latitude,
	clusters = tssites$cl,
	Time = 1
)
cols_gr = cols
PP1 = get_graph_plot(df_cluster_cut,titolo = "Clusters partition map",cols=cols_gr,verbose=0)

vps <- baseViewports()
pushViewport(vps$inner, vps$figure, vps$plot)
# Table grob
grob <-  ggplotGrob(PP1)
grid.draw(grob)
popViewport(3)

dev.off()
}
```

### the rest
```{r}
for(time in time_span){
	cat(crayon::red("Time",time,"\n"))

	df_cluster_cut = df_cluster[df_cluster$Time==time,]
	# clusters_now = df_cluster_cut$clusters
	####### no mode correct if heat plot
	# clusters_now = mode_correct_clusters(clusters_old,clusters_now,very_verbose = 0)
	# se fai heat plot non serve fare la mode correct
	# perché la heat plot la usi per vedere anche i valori di pm10, non la coerenza temporale
	# nei gruppi, che con la heat coloration si perde come visibilità (non so se è chiaro)
	# df_cluster_cut$clusters = clusters_now

	cur_num = sprintf("%02d", time)
	cols = color_correct_clusters(df_cluster_cut,idea=2,verbose=0,nint=15)

	
	### Salso
	salso_out = salso_out_list[[time]]
	ssout = summary(salso_out)
	png(filename=paste0("./figures/",base_folder,"/Salso/Salso-",sprintf("%02d",time),".png"),
		width=600,height=500)
	# plot(ssout,type="heatmap")
	# plot(ssout,type="mds")
	plot(ssout,type="pairs",data=std_sites)
	text(0.3,0.98,paste0("Time ",time," - ",base_folder))
	# plot(ssout,type="dendrogram")
	dev.off()
	
	
	### Graph
	q = get_graph_plot(df_cluster_cut,cols,paste("Cluster map, time",time,"-",base_folder))
	print(q)
	ggsave(file=paste0("./figures/",base_folder,"/Graph/Graph-",cur_num,".png"),
	units="px",width=2000, height=1400, dpi=300)
	dev.off()
	
	
	### Graph and Boxplot
	p = plot_graph_and_hist(df_cluster_cut,cols,titolo=paste("Time",time,"-",base_folder))
	ggsave(file=paste0("./figures/",base_folder,"/Graph and Boxplot/Graph and Boxplot-",cur_num,".png"),
		   plot=p,
		   units="px",width=2500, height=1200, dpi=300) # maybe 1200 is better
		   # units="px",width=2500, height=1400, dpi=300)
	dev.off()
	
	### Covariates
	p = Federica_covariates_plot(df_cluster_cut,cols,
					 titolo = paste("Cluster map, time",time,"-",base_folder),var_selected_idxs)
	ggsave(p,file=paste0("./figures/",base_folder,"/With Covariates/With Covariates-",cur_num,".png"),units="px",width=4500, height=3000, dpi=400)
	dev.off()
}
```








#=======
# ecc
your models when done


#======
# ARI models
need to run almost all the notebook sections for this
```{r}
library(mclust) # if Adjusted RI
LEN = max(time_span)

compare_ARI = function(mod1,mod2){
	ARIvec <- matrix(NA, nrow=1, ncol=LEN)
	for(k in 1: LEN){
		ARIvec[k] <- adjustedRandIndex(salso_out_lists[[mod1]][[k]][1:105],
									   salso_out_lists[[mod2]][[k]][1:105])
	}	
	ncols_ari = 100
	cols_ARI = colora(ncols_ari,79,0)
	# cols_ARI = rev(cols_ARI)
	brks = seq(-1,1,length.out=ncols_ari+1)
	# pdf(paste0("./figures/DRPM/ARI/ari.pdf"), height=8, width=10)
	# svg(paste0("./figures/",base_folder,"/ARI/ari.svg"), height=8, width=10)
	# png(paste0("./figures/",base_folder,"/ARI/ari.png"),  width=700,height=600)
	library(fields)
	plot(1:53,ARIvec,type="l",main=paste0("ARI values - ",mod1," vs ",mod2),ylim=c(-0.5,1))
	abline(h=0,col="gray80",lty=3)
	
	image.plot(ARIvec,
			   main=paste0("ARI values - ",mod1," vs ",mod2),axes=FALSE,col=cols_ARI,
			   breaks=brks)
	mtext(text=c(paste("",1:LEN)), side=2, line=0.3,at=seq(0,1,length=LEN), las=1, cex=0.8)

}

mods = c("DRPM","sPPM","Gaussian PPMx")
compare_ARI(mods[1],mods[2])
compare_ARI(mods[1],mods[3])
compare_ARI(mods[2],mods[3])

# dev.off()
```

