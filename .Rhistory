confini  <- c("Emilia-Romagna","Piemonte","Lombardia","Trentino-Alto Adige","Veneto")
regioni_italiane <- st_read(paste0("./src/plot functions/italia/gadm40_ITA_",details,".shp"))
regioni_italiane_2 <- st_read(paste0("./src/plot functions/italia/gadm40_ITA_",details_altre_regioni,".shp"))
lombardia <- regioni_italiane[regioni_italiane$NAME_1 == "Lombardia",]
altre_regioni <- regioni_italiane_2[regioni_italiane_2$NAME_1 %in% confini,]
shp_map <- st_read(paste0("./src/plot functions/italia/gadm40_ITA_",1,".shp"))
source("plot functions/plot_utilities.R")
source("plot functions/plot_functions.R")
stationPlotgg <- stationPlot()
print(stationPlotgg)
DefaultPlot()
library(drpm)
library(salso)
library(grDevices) # for image saving
# preparation
source("include.R") # for having df_agri
source("plot functions/plotter.R")
source("plot functions/plotter.R")
library(drpm)
library(salso)
library(grDevices) # for image saving
# preparation
source("include.R") # for having df_agri
source("plot functions/plotter.R")
library(drpm)
library(salso)
library(grDevices) # for image saving
# preparation
source("include.R") # for having df_agri
source("plot functions/plotter.R")
library(drpm)
library(salso)
library(grDevices) # for image saving
# preparation
source("include.R") # for having df_agri
source("plot functions/plotter.R")
sites = data.frame(
longitude = unique(df_weekly$Longitude),
latitude = unique(df_weekly$Latitude))
source("include_clusters_functions.R")
stations = unique(df_wsc$IDStations)
y=data.frame()
for(st in stations){
y_we_pm10=cbind(as.data.frame(st),t(df_wsc[which(df_wsc$IDStations==st),"AQ_pm10"]))
y=rbind(y,y_we_pm10)
}
rownames(y) = NULL
colnames(y)<- c("id",paste0("w", 1:53))
df_wsc
y
cols = colora(105,56,show=F)
chosen_variable_name = "AQ_pm10"
trendYearStation_week <- function(file_name){
data_from_to = df_wsc
len_time = 54
chosen_variable = (data_from_to[,chosen_variable_name])
# Crea il grafico ggplot
station_trend <- ggplot(data_from_to,aes(x = week,
y = AQ_pm10,
group=IDStations,
color = as.factor(IDStations))) +
geom_line(show.legend = FALSE) +
labs(x = "Stations", y = chosen_variable_name, title = "Year: 2018 all stations") +
ylim(range(na.omit(chosen_variable))) +
scale_color_manual(values = cols) +
theme_bw()+
theme(panel.grid = element_blank()) +
guides(color = guide_legend())+
labs(x="week")
len_time = (len_time%/%5)
return(trend_animator(file_name,station_trend, data_from_to$week,len_time))
}
trendYearStation_week("None")
std_sites = data.frame(
longitude = unique(df_wsc$Longitude),
latitude = unique(df_wsc$Latitude))
std_sites
plot(sites)
plot(std_sites,col="blue")
time_span = 1:16 # low time span for quick testing, real one will be 1:53
### authors suggested to/did scale the spatial locations and also centered the observations
y_fit = y[,1+time_span]
tps = ncol(y_fit)
y_fit
### and for the scaling of spatial locations we already built
std_sites
# modelPriors = c(m0, s20, Asig, Atau, Alam, a, b, be)
# m0 - mean of phi0, phi0 is the mean of theta, theta is the mean of Y
# s20 - variance of theta, ecc
# Asig - maximum value for sigma
#	[0,Asig] is the support of the uniform in which sigma (std dev of Y) varies
# Atau - maximum value for tau
#	[0,Asig] is the support of the uniform in which mu (mean of Y) varies
# Alam - maximum value for lambda
# lambda is a unuform on [0,Alam]
# lambda is the var of tau, tau is the var of sigma, sigma is the var of Y
# a - shape 1 for alpha
# b - shape 2 for alpha
# b - scale for eta1
modelPriors <- c(0,100, 10, 5, 5, 2, 2, 1)
# m, k0, nu0, L0
# cParms <- c(0,1,5,1)
cParms <- c(0,1,5,1) # as authors
# SIG, TAU, LAM, ETA1, PHI1
# mh <- c(1,1, 1, 0.1, 0.1)
mh <- c(0.1,0.1, 0.7, 0.1, 0.1) # i changed this for sigma2 trace plots
sp <- 4
# niter=50000; nburn=10000; nthin=40 # real one
niter=30000; nburn=15000; nthin=15
nout <- (niter-nburn)/nthin
cat(nout,"valid iterations")
set.seed(1)
models.out <- list()
hh <- 1
# h <- "111"; s <- "0";
model <- "AR1"
# for(s in c("0","1")){ # we want to use space
# authors did also space comparison as it was the paper topic also
models_vector = c("E1P1A1","E1P1A0","E1P0A1","E1P0A0","E0P1A1","E0P1A0","E0P0A1","E0P0A0")
for(h in models_vector){
# readline(prompt="Press [enter] to continue fitting") # to let the pc breath
cat(paste0("fitting model ",hh," (",models_vector[hh],")...\n"))
m.n <- as.numeric(strsplit(h, "")[[1]][c(2,4,6)])
eta1_bool <- m.n[1]!=0
phi1_bool <- m.n[2]!=0
alphat_bool <- m.n[3]!=0
# we select true if the number in h was 1, ie "!=0"
# we always want to use space
# if(s=="0"){
# sc <- NULL
# } else {
sc <- std_sites
# }
tempo_inizio <- Sys.time()
set.seed(1*hh)
sink(nullfile()) # suppress output
out <- drpm_fit(draws=niter, burn=nburn, thin=nthin,
y=y_fit, M=1, s_coords=sc,
# global_alpha=FALSE, # forse intendevano questi due comandi dopo:
unit_specific_alpha=FALSE,
# maybe our tests should be concentrated here
# ie testing with this TRUE or FALSE
time_specific_alpha=alphat_bool, # meaning a bit ambiguos
# Ok after experimenting it means that:
# - if true we let alpha be a param that changes over time.
#	At time 1 we have a chain with some behaviour,
#	at time 2 another chain with another behaviour, ecc
# - if false we instead fix alpha, ie all chains of all times
#	will be the same, as they refer to the same parameter estimation
# The authors in their tests set it to false, ie the fixed alpha
modelPriors=modelPriors,
# ... as testing on this alpha_0 does not seem really relevant
# i mean alpha should always be let able to change
# if we set alpha_0 = TRUE we would never update alpha, but that's not our
# interest (it was in the interest of the paper marketing)
alpha_0 = FALSE,
eta1_0 = eta1_bool,
phi1_0 = phi1_bool,
SpatialCohesion=sp, cParms=cParms,mh=mh,
verbose=FALSE)
sink() # end suppress output
tempo_fine <- Sys.time()
cat(crayon::red("##############################\n"))
cat(crayon::cyan("Model is",paste0(h),"ie:"),
"\neta1_bool =",eta1_bool,"-",
"phi1_bool =",phi1_bool,"-",
"alphat_bool =",alphat_bool,"-",
"\n")
# cat("seed is", 1*hh, "\n")
cat("\n")
differenza_tempo <- tempo_fine - tempo_inizio
cat("Fit took:\n")
print(round(differenza_tempo,digits = 4))
# print(date())
cat(h,"lpml = ", out$lpml, "\n")
cat(h,"waic = ", out$waic, "\n")
cat(crayon::red("##############################\n"))
models.out[[hh]] <- out
names(models.out)[hh] <- paste0("out_",h,"_",model)
# rho <- list()
# for(k in 1:tps){
# 	# rho[[k]] <- salso(t(out$Si[k,,]), loss="VI")
# 	rho[[k]] <- salso(t(out$Si[k,,]), loss="binder")
# }
hh <- hh + 1
}
source("include.R")
library(CARBayesST)
library(sp)
library(proxy)
library(coda)
ordered_by_time <- df_wsc[order(df_wsc$Time), ]
head(ordered_by_time)
colnames(ordered_by_time)
covariates_to_exclude = c("X","IDStations",
"Latitude","Longitude","Time","day","week"
)
covariates=ordered_by_time[,-which(colnames(ordered_by_time)%in% covariates_to_exclude)]
head(covariates)
spatial_coord = ordered_by_time[ordered_by_time$Time=="2018-01-01",c("IDStations","Latitude","Longitude")]
head(spatial_coord)
coordinates(spatial_coord) <- c("Longitude", "Latitude")
# Calculate the pairwise Euclidean distance matrix
dist_matrix <- as.matrix(proxy::dist(coordinates(spatial_coord), method = "Euclidean"))
dim(dist_matrix)
formula = as.formula("AQ_pm10~.")
mod_linear<-ST.CARlinear(formula= formula,
family = "gaussian",
data=covariates,
W= dist_matrix,
burnin = 1000,
n.sample = 25000,
thin=10,
n.chains=1,
n.cores=1,
prior.mean.beta=NULL,
prior.var.beta=NULL,
prior.mean.alpha=NULL,
prior.var.alpha=NULL,
prior.nu2=NULL,
prior.tau2=NULL,
rho.slo=NULL,
rho.int=NULL,
MALA=TRUE,
verbose=TRUE)
mod_AR1<-ST.CARar(formula= formula,
family = "gaussian",
data=covariates,
W= dist_matrix,
burnin = 1000,
n.sample = 25000,
thin=10,
n.chains=1,
n.cores=1,
prior.mean.beta=NULL,
prior.var.beta=NULL,
prior.nu2=NULL,
AR=1, #1 or 2
rho.S=NULL,
rho.T=NULL,
MALA=TRUE,
verbose=TRUE)
mod_AR2<-ST.CARar(formula= formula,
family = "gaussian",
data=covariates,
W= dist_matrix,
burnin = 1000,
n.sample = 25000,
thin=10,
n.chains=1,
n.cores=1,
prior.mean.beta=NULL,
prior.var.beta=NULL,
prior.nu2=NULL,
AR=2, #1 or 2
rho.S=NULL,
rho.T=NULL,
MALA=TRUE,
verbose=TRUE)
model_list = list(mod_linear,mod_AR1,mod_AR2)
mod = model_list[[1]]
summary(mod$samples)
mcmc_matrix = as.matrix(mod$samples$beta)
for(i in 1:dim(mcmc_matrix)[2]){
plot(mcmc_matrix[,i],type="l",cex.axis=0.8)
}
mcmc_matrix = as.matrix(mod$samples$rho)
for(i in 1:dim(mcmc_matrix)[2]){
plot(mcmc_matrix[,i],type="l",cex.axis=0.8)
}
summary_results = mod$summary.results
summary_results = data.frame(summary_results)
# Identify variables with credible intervals excluding zero
selected_variables <- summary_results[summary_results$X2.5. > 0 | summary_results$X97.5. < 0, ]
print(selected_variables)
mod$accept
# Create an empty matrix with specified row and column names
metrics_matrix <- matrix(NA, nrow = 4, ncol = 6, dimnames = list(c("linear", "ar1", "ar2", "ar adaptive"), c("DIC", "p.d", "WAIC", "p.w", "LMPL", "loglikelihood")))
k = 1
for (mod in model_list) {
metrics_matrix[k, ] <- mod$modelfit
k = k + 1
}
# Convert the matrix to a data frame if needed
metrics_dataframe <- as.data.frame(metrics_matrix)
metrics_dataframe[,c(3,5)]
model_list = list(mod_linear,mod_AR1,mod_AR2)
mod = model_list[[2]]
mcmc_matrix = as.matrix(mod$samples$beta)
for(i in 1:dim(mcmc_matrix)[2]){
plot(mcmc_matrix[,i],type="l",cex.axis=0.8)
}
burnin = 2500
n_sample = 40000
mod_AR1<-ST.CARar(formula= formula,
family = "gaussian",
data=covariates,
W= dist_matrix,
burnin = burnin,
n.sample = n_sample,
thin=10,
n.chains=1,
n.cores=1,
prior.mean.beta=NULL,
prior.var.beta=NULL,
prior.nu2=NULL,
AR=1, #1 or 2
rho.S=NULL,
rho.T=NULL,
MALA=TRUE,
verbose=TRUE)
mod_AR2<-ST.CARar(formula= formula,
family = "gaussian",
data=covariates,
W= dist_matrix,
burnin = burnin,
n.sample = n_sample,
thin=10,
n.chains=1,
n.cores=1,
prior.mean.beta=NULL,
prior.var.beta=NULL,
prior.nu2=NULL,
AR=2, #1 or 2
rho.S=NULL,
rho.T=NULL,
MALA=TRUE,
verbose=TRUE)
model_list = list(mod_linear,mod_AR1,mod_AR2)
saveRDS(model_list, file = "models_CARBayesST.RData")
mod = model_list[[2]]
mcmc_matrix = as.matrix(mod$samples$beta)
for(i in 1:dim(mcmc_matrix)[2]){
plot(mcmc_matrix[,i],type="l",cex.axis=0.8)
}
summary_results = mod$summary.results
summary_results = data.frame(summary_results)
# Identify variables with credible intervals excluding zero
selected_variables <- summary_results[summary_results$X2.5. > 0 | summary_results$X97.5. < 0, ]
print(selected_variables)
mod$accept
# Create an empty matrix with specified row and column names
metrics_matrix <- matrix(NA, nrow = 4, ncol = 6, dimnames = list(c("linear", "ar1", "ar2", "ar adaptive"), c("DIC", "p.d", "WAIC", "p.w", "LMPL", "loglikelihood")))
k = 1
for (mod in model_list) {
metrics_matrix[k, ] <- mod$modelfit
k = k + 1
}
# Convert the matrix to a data frame if needed
metrics_dataframe <- as.data.frame(metrics_matrix)
metrics_dataframe[,c(3,5)]
mod = model_list[[3]]
mcmc_matrix = as.matrix(mod$samples$beta)
for(i in 1:dim(mcmc_matrix)[2]){
plot(mcmc_matrix[,i],type="l",cex.axis=0.8)
}
summary_results = mod$summary.results
summary_results = data.frame(summary_results)
# Identify variables with credible intervals excluding zero
selected_variables <- summary_results[summary_results$X2.5. > 0 | summary_results$X97.5. < 0, ]
print(selected_variables)
mod$accept
# Create an empty matrix with specified row and column names
metrics_matrix <- matrix(NA, nrow = 4, ncol = 6, dimnames = list(c("linear", "ar1", "ar2", "ar adaptive"), c("DIC", "p.d", "WAIC", "p.w", "LMPL", "loglikelihood")))
k = 1
for (mod in model_list) {
metrics_matrix[k, ] <- mod$modelfit
k = k + 1
}
# Convert the matrix to a data frame if needed
metrics_dataframe <- as.data.frame(metrics_matrix)
metrics_dataframe[,c(3,5)]
resid = residuals(mod)
plot(resid,type="l")
print(rownames(selected_variables))
print(rownames(selected_variables)[1:20])
summary_results
print(rownames(selected_variables)[1:20])
EM_covariates_to_exclude = grep("EM",colnames(ordered_by_time))
EM_covariates_to_exclude
EM_covariates_to_exclude = colnames(ordered_by_time)[grep("EM",colnames(ordered_by_time))]
EM_covariates_to_exclude
all_covar = colnames(ordered_by_time)
covariates_to_exclude = c("X","IDStations",
"Latitude","Longitude","Time","day","week"
)
EM_covariates_to_exclude =all_covar[grep("EM",all_covar)]
covariates=ordered_by_time[,-which(all_covar%in% covariates_to_exclude)]
head(covariates)
covariates_to_exclude = c(covariates_to_exclude,EM_covariates_to_exclude)
covariates=ordered_by_time[,-which(all_covar%in% covariates_to_exclude)]
head(covariates)
all_covar = colnames(ordered_by_time)
covariates_to_exclude = c("X","IDStations",
"Latitude","Longitude","Time","day","week"
)
EM_covariates_to_exclude =all_covar[grep("EM_",all_covar)]
covariates_to_exclude = c(covariates_to_exclude,EM_covariates_to_exclude)
covariates=ordered_by_time[,-which(all_covar%in% covariates_to_exclude)]
head(covariates)
EM_covariates_to_exclude
spatial_coord = ordered_by_time[ordered_by_time$Time=="2018-01-01",c("IDStations","Latitude","Longitude")]
head(spatial_coord)
coordinates(spatial_coord) <- c("Longitude", "Latitude")
# Calculate the pairwise Euclidean distance matrix
dist_matrix <- as.matrix(proxy::dist(coordinates(spatial_coord), method = "Euclidean"))
dim(dist_matrix)
formula = as.formula("AQ_pm10~.")
burnin = 2500
n_sample = 40000
mod_AR1<-ST.CARar(formula= formula,
family = "gaussian",
data=covariates,
W= dist_matrix,
burnin = burnin,
n.sample = n_sample,
thin=10,
n.chains=1,
n.cores=1,
prior.mean.beta=NULL,
prior.var.beta=NULL,
prior.nu2=NULL,
AR=1, #1 or 2
rho.S=NULL,
rho.T=NULL,
MALA=TRUE,
verbose=TRUE)
mod_AR2<-ST.CARar(formula= formula,
family = "gaussian",
data=covariates,
W= dist_matrix,
burnin = burnin,
n.sample = n_sample,
thin=10,
n.chains=1,
n.cores=1,
prior.mean.beta=NULL,
prior.var.beta=NULL,
prior.nu2=NULL,
AR=2, #1 or 2
rho.S=NULL,
rho.T=NULL,
MALA=TRUE,
verbose=TRUE)
model_list = list(mod_linear,mod_AR1,mod_AR2)
saveRDS(model_list, file = "models_CARBayesST.RData")
mod = model_list[[2]]
summary_results = mod$summary.results
summary_results = data.frame(summary_results)
# Identify variables with credible intervals excluding zero
selected_variables <- summary_results[summary_results$X2.5. > 0 | summary_results$X97.5. < 0, ]
print(selected_variables)
print(rownames(selected_variables)[1:20])
# Create an empty matrix with specified row and column names
metrics_matrix <- matrix(NA, nrow = 4, ncol = 6, dimnames = list(c("linear", "ar1", "ar2", "ar adaptive"), c("DIC", "p.d", "WAIC", "p.w", "LMPL", "loglikelihood")))
k = 1
for (mod in model_list) {
metrics_matrix[k, ] <- mod$modelfit
k = k + 1
}
# Convert the matrix to a data frame if needed
metrics_dataframe <- as.data.frame(metrics_matrix)
metrics_dataframe[,c(3,5)]
summary(mod$samples)
summary_results = mod$summary.results
summary_results = data.frame(summary_results)
# Identify variables with credible intervals excluding zero
selected_variables <- summary_results[summary_results$X2.5. > 0 | summary_results$X97.5. < 0, ]
print(selected_variables)
print(rownames(selected_variables)[1:20])
print(rownames(selected_variables)[1:23])
print(selected_variables)
mod$accept
# Create an empty matrix with specified row and column names
metrics_matrix <- matrix(NA, nrow = 4, ncol = 6, dimnames = list(c("linear", "ar1", "ar2", "ar adaptive"), c("DIC", "p.d", "WAIC", "p.w", "LMPL", "loglikelihood")))
k = 1
for (mod in model_list) {
metrics_matrix[k, ] <- mod$modelfit
k = k + 1
}
# Convert the matrix to a data frame if needed
metrics_dataframe <- as.data.frame(metrics_matrix)
metrics_dataframe[,c(3,5)]
resid = residuals(mod)
plot(resid,type="l")
mod$summary.results
summary_results
var_removed = summary_results[!(selected_variables%in%rownames(summary_results))]
var_removed
var_removed = summary_results[!(selected_variables%in%rownames(summary_results))]
selected_variables
var_removed = summary_results[!(rownames(selected_variables)%in%rownames(summary_results))]
var_removed
var_removed = summary_results[!(rownames(selected_variables)%in%rownames(summary_results)),]
var_removed
rownames(selected_variables)%in%rownames(summary_results)
rownames(selected_variables)
rownames(summary_results)
var_removed = summary_results[!(rownames(summary_results)%in%rownames(selected_variables)),]
var_removed
print(selected_variables)
summary_results = mod$summary.results
summary_results = data.frame(summary_results)
# Identify variables with credible intervals excluding zero
selected_variables <- summary_results[summary_results$X2.5. > 0 | summary_results$X97.5. < 0, ]
print(selected_variables)
print(rownames(selected_variables)[1:23])
var_removed = summary_results[!(rownames(summary_results)%in%rownames(selected_variables)),]
print(var_removed)
summary_results = mod$summary.results
a = 2
a
